#NCS데이터 탐색
#모집단 - 분석을 하기 위해 관심이 있는 대상 전체
#         추출단위가 유한/무한한 유한/무한 모집단
#표본추출 - 모집단의 부분 집합을 추출하는 것
#           모집단 전체에 대한 분석이 사실상 불가능하다는 제약
#           전수 조사를 하면 오히려 막대한 비용/시간 소요
#통계분석- 표본이 가지고 있는 모집단 성질의 일부만을
#           가지고 모집단의 특성을 합리적으로 추론하는것
#모수 - 모집단의 통계적 속성을 나타내는 수치
#데이터의 위치 정보를 나타내는 평균, 중앙값
#데이터 분포에 대한 지표인 분산 및 표준 편차

#통계분석의 과정은 총 6단계로 구성
#표본 추출 기법
#단순 무작위 추출
#모집단에서 정해진 규칙없이 표본을 추출하는 방식
#100개의 전구에서 무작위로 10개의 전구를 호출

#계통추출
#모집단을 일정한 간격으로 추출하는 방식
#100명의 사람에게 번호표를 나눠주고
#끝자리가 7로 끝나는 사람들을 선정

#층화추출
#모집단을 여러계층으로 나누고, 계층별로 무작위 추출을
#수행하는 방식
#조사 지역을 도별로 나누고,
#각 도에서 무작위로 100명씩선정

#군집추출
#모집단을 여러 군집으로 나누고,
#일부 군집의 전체를 추출하는 방식
#100개의 전구에 무작위로 검은색, 노란색, 파란색을
#칠하고 파란색의 전구를 모두 추출

#측정
#관심있는 대상을 분석 목적에 맞게 데이터화하는것
#명목척도 - 이메일주소, 인터넷계정, 옷색깔, 성별
#순서척도 -직급, 영화평점, 선호도
#구간척도 - 온도, 지능지수
#비율척도 - 질량, 나이, 개수, 길이

#잡음
#대상이 잘못 측정하게 해서 참값에서 벗어나게 만드는 임의의 존

#기초통계기법
# 평균(mean) - 
# 중앙값(median) - 데이터 집합을 크기에 따라 차례로 나열했을때 가운데놓이는값
# 최빈치(mode) -가장 많은 빈도를 갖는 데이터를 의미
# 분산(variance) - 평균으로부터 각각의 데이터가 얼마나 떨어져있는지를 종합적으로 나타내는 지표
# 표준편차(standard Deviation) - 데이터 집합의 확산정도를 나타내는 분산의 단위를 본래의 척도와
#                              - 맞춰주기위해 분산을 제곱근 한 것
# 범위(Range) - 데이터 집합에서 최대값과 최소값을 이용해서 확산정도를 간단하게 나타낸값
#히스토그램 - 단일 속성에 대한  데이터 ㅍ분포를 시각적으로 알기위해 주로사용되는 그래프

#박스수염 그래프 - 데이터집합의 최대값, 최소값, 중앙값, 사분편차를 사용하여
#                   데이터들이 어떤모양으로 분포되어 있으며, 
#                   극단값들이 어떤지를 쉽게 알 수 있도록 하는 그림


#예제) 사람들이 사용하고 있는 스마트폰의 제조사와
#       디스플레이 크기, 출시연도,구매시기 등의 3가지 속성에 대한 표를만들고
#      기재하여 데이터 집합을 얻는다. R을 이용하여 수집된 데이터를 분석할 때
#       테이블의 형태로 데이터를 읽어 들이기 위해
#     .csv 파일의 형태로 저장한다.
phone <- read.csv('c:/JAVA/phone-01.csv', header= F)
summary(phone) #기술통계 요약

var(phone) #분산
sqrt(var(phone)) #표준편차(분산의 제곱근)

hist(phone$V1) #출시년도 빈도
hist(phone$V2) #구매시기 빈도
hist(phone$V3) #화면크기 빈도

#상관분석
#두 변수간의 선형적인 관계를 정량적인 지표
#두 변수 간의 상관 정도를 나타내는 공분산을 이용
#공분산은 한변수가 상승할 때 나머지변수가 상승하는 경향이 존재하면 양의 값을 갖고,
#하강하는 경향이 존재하면 음의 값을 갖는다
#예) 연령에 따른 스마트폰 데이터 사용량을 알고자 할 때

#상관계수
#두모집단을 나타내는 변수 x1,x2 간의
#각 변수의 표준편차의 곱으로 나누어 주어
#선형관계의 정도를 표현
#실제 데이터는 모집단 일부분이기 때문에 표본 상관계수를 사용
#- 피어슨 상관계수

#회귀분석
#한 변수가 다른변수에 미치는 영향을 함수 형태로
#추정하기 위해 고안된 기법
#한 변수가 다른 변수에 1차원 혹은 2차원 이상의
#영향을 주고 있다는 가정 아래 수행
#영향을 주는 변수 - 독립변수
#영향을 받는 변수 - 종속변수

#예) 스마트폰에 설치된 애플리케이션의 개수가 데이터 사용량에 미치는영향 분

#단순회귀분석- 독립변수가 1개이며 종속변수와의 관계가
#선형적(1차함수) 독립변수 x1이 종속변수 y에 선형적인 영향을 미친다는가정

#다중회귀분석- 독립변수가 2개이상이며 종속변수와의 관계가
#선형적(1차함수) n 개의 변수가 y에 선형적인 영향을 미친다는가정

#곡선회귀분석- 독립변수가 1개 이며 종속변수와의 관계가 곡선적(2차함수이상)  
#독립변수 x1이 y에 k차원 함수형태

#회귀분석시 변수들의 유의차 검증
#데이터를 이용한 회귀분석을 수행할 때,
#독립변수 x1,x2,...,xn 들에 대한 분ㄴ산 분석결과에서
#p-value > 0.05 인 변수들은 종속변수 y에 대해 유의한 것으로 판

#수집된 데이터의 변수들과 데이터 사용량에대한 유의성파악
phone02 <- read.table('c:/JAVA/phone-02.csv',
                      header = F,sep=',')

#공분산으로 상관계수를 측정
cor(phone02)

#데이터 사용량 V9은 평균 스마트폰 사용시간 V7과
#상관관계 유의미

#가장 높은 유의성을 갖는 변수가 데이터 사용량에 미치는 영향을 추정하여 단순회귀분석 실시.
p<-lm(phone2$V9~phone2$V7, data=phone2)
#회귀식 : y= -272.001 + 6.283*phone2$V7
summary(p)
plot(phone2$V9, phone2$V7, xlab='데이터 사용량', ylab='평균스마트폰 사용시')

#변수간 관계확인
#분석모형 구축시 유의사항
#변수의 유의성 검증 후 유의성이 높은 최소한의
#변수들로 분석 모형을 검증

#분석 모형을 구축하는 데에는 [일반화 오류]와
#[훈련 오류]라는 두 가지 종류의 오류가 발생

#일반화 오류- 분석 모형을 만들 때 
#             주어진 데이터 집합의 특성을 지나치게 반영 (과적합)
#  훈련 오류- 주어진 데이터 집합에 부차적인 특성과 잡음이 있다는 점을
#             고려하여 특성을 덜 반영(미적합)

#분석모형 검증
#모집단에서 표본 추출한 데이터 집합을 이용하여
#모집단을 합리적으로 추론하는 타당한 분석 모형을 구축 
# -일반호/훈련 오류를 모두 고려

#분석 모형에서 산출된 값과 실제 값과의 차이의
#제곱 평균을 예측 오차로 계산(RMSE)하여 수행 

#분석 모형의 타당성 평가
#분석 모형이 실제로 현실을 잘 묘사하고 있는지 확인

#주어진 데이터를 모형에 입력하여 얻은 결과와
#실제 데이터값 간의 차이가 적으면 좋은 모형 


#분석모형 보정
#시뮬레이션 분석 모형이 유효한지 판단하기 위해
#시뮬레이션을 통해 모형의 타당성과 적합성을 평가
#시뮬레이션 결과가 실제 데이터값과 차이가 크면
#분석모형 재검토/수정 필요 

#무작위 추출을 통해 7:3 비율로 train/test 데이터 준비
s<-read.table('c:/JAVA/phone-02.csv',
                    header=F, sep=',')
for (i in 1:5){
  tr<-sample(nrow(s), replace=F,size=nrow(s)*0.7)


#학습/훈련데이터 추출
  s_train<-s[tr, ]
  s_test<-s[-tr, ]

#회귀모형 구축 - 학습 데이터 집합사용, 회귀식 작성
  lm(s_train[,9]~s_train[,7], data=s_train)

#y = -372.504+(7.386 * x)

#회귀식을 함수로 만들고 시험 데이터로 확인
lrm<-function(x){
  -290.278+(6.255 * x)
}
test_result<-lrm(s_test[,7])    #추정치

#RMSE 계산
  rmse<-sum(abs(s_test[,7] - lrm(s_test[,7]))) / sqrt(nrow(s_test))
  print(rmse)
} #for 문 닫기 


#데이터 정제하기 
#데이터 유형 추출 -which
l2016<-which(s[,1]==2016)  #2016 출시상품 index 표시
s[l2016,]                 #2016 출시상품 출력

#특정범위 데이터 추출
gt_500<-s[,9]>=500         #일일데이터사용량 500MB이상
s[gt_500,]

#일일 데이터사용량[9]이 400MB 이상인 샘플
gt_400<-s[,9]>=400
s[gt_400,]

#일일 데이터사용량이 400MB 이하인 샘플
lt_400<-s[,9]<400
s[lt_400,]

#KNN 알고리즘 군집화
#차종,마력,경기용차여부,빠른지여부
#혼다어코드,180,F,F
#유고, 500,F,F
#드롤리안,200,F,F
#쉬보레카미로,400,T,?

#유클리드 거리측정 이용 sqrt((p1-p3)**2 + (p2-p4)**2)
#차종,마력, 빠른지여부
#혼다어코드,180(p1),0(p2) :
#유고,500(p3),1(p4)
#드롤리안,200,0
#쉬보레카미로,400,?


km3<-kmeans(s[,9],3)
km3$cluster     #군집 벡터값 출력
km3$centers     #군집 벡터값 평균 
s_km3<-cbind(s,km3$cluster)
s_km3


km5<-kmeans(s[,9],5)
km5 
km5$cluster     #군집 벡터값 출력
km5$centers     #군집 벡터값 평균 
km5_cluster<-km5$cluster

for(i in 1:5) {
  km5_cluster[km5_cluster == i] <-km5$centers[i]
}
s_km5<-cbind(s,km5_cluster)   #평균값 대체
s_km5

#데이터 정제
#데이터를 불완전하게 만드는 요소
#원시 데이터에는 보통 결측치(missing value)와 잡음 존재

#결측치 - 샘플에서 누락된 변수값을 지칭 
#오류로 인해 발생할 수도 있지만, 단순히 조사 대상이 측정을 원하지 않을 때에도
#발생 
#해결방법:  샘플제거, 해당 변수 제거,
#결측치 무시, 결측치 추정(평균,중앙값,회귀분석)

#이상치- 데이터집합에서 대부분의 다른 샘플과 현저한 차이를 나타내는 샘플, 
#변수값 오류면 제거, 이상치면 관심을 가지며 분석 시행 



